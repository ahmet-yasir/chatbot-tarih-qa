 # ğŸ‡¹ğŸ‡· Cumhuriyet Tarihi Chatbotu

Bu proje, TÃ¼rkiye Cumhuriyeti tarihi hakkÄ±nda sorulan sorulara **Wikipedia verileri** Ã¼zerinden cevap verebilen, **RAG (Retrieval-Augmented Generation)** tabanlÄ± bir yapay zeka sohbet botudur.

Streamlit arayÃ¼zÃ¼ Ã¼zerinden Ã§alÄ±ÅŸan sistem; Vikipedi'den alÄ±nan Cumhuriyet dÃ¶nemi iÃ§eriklerini kullanarak, kullanÄ±cÄ±dan gelen sorularÄ± ilgili paragraflarla eÅŸleÅŸtirip **Google Gemini LLM** Ã¼zerinden cevap Ã¼retir.

---

## Ã–zellikler

- ğŸ” Soruya uygun iÃ§erikleri FAISS ile vektÃ¶r tabanlÄ± arar
- ğŸ¤– Gemini LLM kullanarak doÄŸal dilde yanÄ±tlar Ã¼retir
- ğŸ‡¹ğŸ‡· TÃ¼m iÃ§erikler ve cevaplar TÃ¼rkÃ§edir
- ğŸ“š Wikipediaâ€™dan otomatik veri Ã§ekme ve iÅŸleme sistemi
- ğŸ§© ModÃ¼ler yapÄ±: veri Ã§ekme, Ã¶n iÅŸleme, embedding, sorgulama ayrÄ± ayrÄ± kontrol edilebilir

---

##  Proje YapÄ±sÄ±
chatbot-tarih-qa/  
â”œâ”€â”€ app/  
â”‚ â”œâ”€â”€ document_loader.py  
â”‚ â”œâ”€â”€ retriever.py  
â”‚ â”œâ”€â”€ llm_setup.py  
â”‚ â””â”€â”€ streamlit_app.py  
â”œâ”€â”€ build_vector_index.py  
â”œâ”€â”€ scripts/  
â”‚ â”œâ”€â”€ download_from_wikipedia.py  
â”‚ â”œâ”€â”€ extract_paragraphs.py  
â”‚ â””â”€â”€ convert_txt_to_jsonl.py  
â”œâ”€â”€ data/  
â”‚ â”œâ”€â”€ raw/  
â”‚ â”œâ”€â”€ processed/  
â”‚ â””â”€â”€ extracted/  
â”œâ”€â”€ vectorstore/  
â”œâ”€â”€ .env  
â”œâ”€â”€ requirements.txt  
â””â”€â”€ README.md  

##  Kurulum

> âš ï¸ **UyarÄ±:** Bu proje yalnÄ±zca **Python 3.10** sÃ¼rÃ¼mÃ¼yle test edilmiÅŸtir.  
> Daha yeni sÃ¼rÃ¼mlerde (Ã¶rn. Python 3.11 veya 3.12) bazÄ± baÄŸÄ±mlÄ±lÄ±klarÄ±n Ã§alÄ±ÅŸmamasÄ± mÃ¼mkÃ¼ndÃ¼r.  
> LÃ¼tfen `conda` veya `pyenv` gibi bir araÃ§la Python 3.10 ortamÄ± oluÅŸturunuz.

### Conda OrtamÄ± OluÅŸturma (Ã–nerilen)

```bash
conda create -n chatbot-tarih-qa python=3.10
conda activate chatbot-tarih-qa
```

### 1. Reponun KlonlanmasÄ±

```bash
git clone https://github.com/ahmet-yasir/chatbot-tarih-qa.git
cd chatbot-tarih-qa
```

### 2. Gerekli KÃ¼tÃ¼phanelerin Kurulumu

> âš ï¸ **Not:** FAISS kÃ¼tÃ¼phanesi bu projede zorunludur.  
> `requirements.txt` dosyasÄ±na `faiss-cpu` eklenmiÅŸtir.  
> EÄŸer CUDA destekli bir sistem kullanÄ±yorsanÄ±z, `faiss-cpu` yerine `faiss-gpu` kurmanÄ±z gerekebilir.

```bash
pip install -r requirements.txt
```

### 3. `.env` DosyasÄ±nÄ± OluÅŸturun

Proje dizinine `.env` adÄ±nda bir dosya oluÅŸturun ve iÃ§ine aÅŸaÄŸÄ±daki satÄ±rÄ± ekleyin:

```bash
GEMINI_API_KEY=your_gemini_api_key_here
```

> ğŸ”‘ **Not:** Google Gemini API anahtarÄ±nÄ±zÄ± [Google AI Studio](https://makersuite.google.com/app) Ã¼zerinden Ã¼cretsiz olarak alabilirsiniz.

##  Veri Seti HazÄ±rlama

Veri seti iki farklÄ± yÃ¶ntemle elde edilebilir:

---

### YÃ¶ntem 1: Otomatik Wikipedia'dan Veri Ã‡ekme (Script ile)

Bu yÃ¶ntemde proje iÃ§inde bulunan `scripts/` dizisindeki hazÄ±r Python betikleri ile Wikipediaâ€™dan doÄŸrudan veriler Ã§ekilir ve iÅŸlenir.

#### 1. Wikipedia Ä°Ã§eriÄŸini Ä°ndir

```bash
python scripts/download_from_wikipedia.py
```
Bu script seÃ§ilen Cumhuriyet tarihi baÅŸlÄ±klarÄ± data/raw/ klasÃ¶rÃ¼ne .txt dosyalarÄ± olarak kaydeder.

#### 2. ParagraflarÄ± AyÄ±kla

```bash
python scripts/extract_paragraphs.py
```
Bu script paragraflarÄ± Ã§Ä±karÄ±r ve data/processed/rag_paragraflar.txt dosyasÄ±na yazar.

#### 3. JSONL FormatÄ±na DÃ¶nÃ¼ÅŸtÃ¼r

```bash
python scripts/convert_txt_to_jsonl.py
```
Bu script ile data/extracted/ klasÃ¶rÃ¼ne her paragraf ayrÄ± bir .jsonl satÄ±rÄ± olarak kaydedilir.

### YÃ¶ntem 2: HazÄ±r Veri Seti (Kaggle veya Drive)
Zaman kazanmak iÃ§in Ã¶nceden hazÄ±rlanmÄ±ÅŸ .jsonl formatÄ±ndaki Cumhuriyet tarihi veri setini doÄŸrudan indirebilirsiniz.

### HazÄ±r JSONL Veri Seti - Kaggle
Zaman kazanmak iÃ§in Ã¶nceden hazÄ±rlanmÄ±ÅŸ .jsonl formatÄ±ndaki Cumhuriyet tarihi veri setini doÄŸrudan indirebilirsiniz.

<a href="https://www.kaggle.com/datasets/ayasir/cumhuriyet-tarihi-belgeleri" target="_blank">HazÄ±r JSONL veri seti - Kaggle</a>

Ä°ndirdikten sonra data/extracted/ klasÃ¶rÃ¼ne yerleÅŸtirmeniz yeterlidir:

## VektÃ¶r VeritabanÄ± OluÅŸturma

Veriler `.jsonl` formatÄ±nda hazÄ±rlandÄ±ktan sonra, embedding (vektÃ¶rleÅŸtirme) iÅŸlemi gerÃ§ekleÅŸtirilir. Bu iÅŸlem sonucunda FAISS formatÄ±nda bir vektÃ¶r veritabanÄ± oluÅŸturulur.

AÅŸaÄŸÄ±daki komutu kullanarak veritabanÄ±nÄ± oluÅŸturabilirsiniz:

```bash
python build_vector_index.py
```
Bu komut ÅŸunlarÄ± yapar:
- data/extracted/ klasÃ¶rÃ¼nden belgeleri yÃ¼kler.
- sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 modeli ile her belgeyi  vektÃ¶rleÅŸtirir.
- VektÃ¶rleri FAISS kullanarak vectorstore/faiss_index/ klasÃ¶rÃ¼ne kaydeder.

##  UygulamanÄ±n BaÅŸlatÄ±lmasÄ±

TÃ¼m kurulumlar tamamlandÄ±ktan ve vektÃ¶r veritabanÄ± oluÅŸturulduktan sonra, Streamlit arayÃ¼zÃ¼nÃ¼ baÅŸlatmak iÃ§in aÅŸaÄŸÄ±daki komutu Ã§alÄ±ÅŸtÄ±rÄ±n:

```bash
streamlit run app/streamlit_app.py
```
Komut Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ktan sonra tarayÄ±cÄ±nÄ±zda otomatik olarak bir arayÃ¼z aÃ§Ä±lÄ±r. Bu arayÃ¼z Ã¼zerinden sorularÄ±nÄ±zÄ± sorabilirsiniz.

## ğŸ§ª Ã–rnek KullanÄ±m

AÅŸaÄŸÄ±da uygulamanÄ±n Ã§alÄ±ÅŸma Ã¶rneÄŸini gÃ¶rebilirsiniz:

### ğŸ–¼ï¸ Ekran GÃ¶rÃ¼ntÃ¼sÃ¼

![Chatbot Ekran GÃ¶rÃ¼ntÃ¼sÃ¼](screenshots/ornek.png)

> GÃ¶rselde, kullanÄ±cÄ± tarafÄ±ndan yazÄ±lan soruya sistemin Wikipedia kaynaklarÄ±yla nasÄ±l yanÄ±t verdiÄŸi gÃ¶sterilmektedir.
